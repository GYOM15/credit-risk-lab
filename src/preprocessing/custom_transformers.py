# -*- coding: utf-8 -*-
"""custom_transformers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xEtFVZJoGpyikTW5dvZuvrKwva6mE6wS

# FICHIER DES TRANSFORMERS
"""

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, RobustScaler
from sklearn.pipeline import Pipeline
from pandas.api.types import is_numeric_dtype
from scipy.stats import skew
import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module='sklearn.pipeline')

# ==============================================================================
# NETTOYAGE DES INTRUS
# ==============================================================================
class DataCleaningTransformer(BaseEstimator, TransformerMixin):
    """
    Nettoie les valeurs intruses en utilisant vos fonctions existantes.
    """
    def __init__(self, generic_missing_values=None):
        if generic_missing_values is None:
            self.generic_missing_values = ['-', '?', 'null', '', 'NaN', 'none', '--']
        else:
            self.generic_missing_values = generic_missing_values

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        """Remplace les valeurs intruses par np.nan."""
        X_copy = X.copy()

        # Utilisation de votre logique de remplacement
        for col in X_copy.columns:
            if X_copy[col].dtype == 'object':
                X_copy[col] = X_copy[col].replace(self.generic_missing_values, np.nan)

        return X_copy

# ==============================================================================
# TRANSFORMER 1 : FEATURE ENGINEERING
# ==============================================================================
class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):
    """
    Crée le ratio Epargne/Salaire et gère les infinis.
    """
    def __init__(self):
        self.feature_names_out_ = None

    def fit(self, X, y=None):
        # On stocke les colonnes d'entrée + la nouvelle colonne
        self.feature_names_out_ = X.columns.tolist() + ['Ratio_Epargne_Salaire']
        return self

    def transform(self, X):
        X_copy = X.copy()

        # Création du ratio
        X_copy['Ratio_Epargne_Salaire'] = (
            X_copy['Epargne_Totale'] / X_copy['Salaire_Annuel'].replace(0, np.nan)
        )
        # On drop l'épargne (colinéarité) avec le montant
        X_copy.drop(columns=['Epargne_Totale'], inplace=True)

        # Conversion des infinis en NaN
        X_copy.replace([np.inf, -np.inf], np.nan, inplace=True)

        return X_copy


# ==============================================================================
# TRANSFORMER 2 : IMPUTATION INTELLIGENTE
# ==============================================================================
class SmartImputerTransformer(BaseEstimator, TransformerMixin):
    """
    Imputation intelligente selon le type de variable :
    - Numériques : Médiane si skew > 0.5, sinon Moyenne
    - Catégorielles : Mode (ou "Inconnu" si >10% manquant)
    - Ordinales : Médiane sur les codes ordinaux
    """
    def __init__(self, dict_ordinals=None, skew_threshold=0.5, seuil_inconnu=10):
        self.dict_ordinals = dict_ordinals or {}
        self.skew_threshold = skew_threshold
        self.seuil_inconnu = seuil_inconnu
        self.imputation_values = {}  # Stocke les valeurs calculées

    def _analyser_numerique(self, df, col):
        """Décide médiane ou moyenne selon le skew."""
        serie = df[col].dropna()
        if serie.empty:
            return np.nan

        skewness = skew(serie)
        if abs(skewness) > self.skew_threshold:
            return serie.median()
        else:
            return serie.mean()

    def _analyser_categorielle(self, df, col):
        """Décide mode ou 'Inconnu' selon % de valeurs manquantes."""
        pct_manquant = df[col].isnull().mean() * 100
        if pct_manquant >= self.seuil_inconnu:
            return "Inconnu"
        else:
            mode_val = df[col].mode(dropna=True)
            return mode_val[0] if not mode_val.empty else "Inconnu"

    def _analyser_ordinale(self, df, col, ordre):
        """Calcule la médiane sur les codes ordinaux."""
        temp_serie = pd.Categorical(df[col], categories=ordre, ordered=True)
        codes = temp_serie.codes
        valid_codes = codes[codes != -1]

        if len(valid_codes) > 0:
            median_idx = int(round(pd.Series(valid_codes).median()))
            return ordre[median_idx]
        else:
            mode_val = df[col].mode()
            return mode_val[0] if not mode_val.empty else ordre[0]

    def fit(self, X, y=None):
        """Apprend les valeurs d'imputation sur le Train."""
        for col in X.columns:
            if col in self.dict_ordinals:
                # Ordinale
                valeur = self._analyser_ordinale(X, col, self.dict_ordinals[col])
            elif is_numeric_dtype(X[col]):
                # Numérique
                valeur = self._analyser_numerique(X, col)
            else:
                # Catégorielle
                valeur = self._analyser_categorielle(X, col)

            # Stockage de la valeur calculée
            self.imputation_values[col] = valeur

        return self

    def transform(self, X):
        """Applique l'imputation apprise MANUELLEMENT (pas via SimpleImputer)."""
        X_copy = X.copy()

        for col, valeur in self.imputation_values.items():
            if col in X_copy.columns:
                # Imputation directe avec fillna (évite les problèmes de dtype)
                X_copy[col] = X_copy[col].fillna(valeur)

        return X_copy


# ==============================================================================
# TRANSFORMER 3 : ENCODAGE PERSONNALISÉ
# ==============================================================================
class CustomEncodingTransformer(BaseEstimator, TransformerMixin):
    """
    Encodage personnalisé :
    - Niveau_Etude : OrdinalEncoder
    - Ville : Filtrage top villes + OneHotEncoder
    """
    def __init__(self, ordre_etudes=None, seuil_ville=10, couverture_ville=0.85):
        self.ordre_etudes = ordre_etudes or ['bac', 'licence', 'master', 'doctorat']
        self.seuil_ville = seuil_ville
        self.couverture_ville = couverture_ville
        self.top_villes = []
        self.ordinal_encoder = None
        self.onehot_encoder = None

    def _nettoyer_texte(self, text):
        """Supprime les accents, minuscules."""
        import unicodedata
        if not isinstance(text, str):
            return text
        text = unicodedata.normalize('NFD', text)
        text = "".join([c for c in text if unicodedata.category(c) != 'Mn'])
        return text.lower().strip()

    def _get_top_villes(self, df, col):
        """Calcule les villes dominantes sur le Train."""
        counts = df[col].value_counts()
        cum_pct = counts.cumsum() / len(df)
        return counts[(counts >= self.seuil_ville) | (cum_pct <= self.couverture_ville)].index.tolist()

    def fit(self, X, y=None):
        """Apprend l'encodage sur le Train."""
        X_copy = X.copy()

        # Nettoyage des textes
        if 'Ville' in X_copy.columns:
            X_copy['Ville'] = X_copy['Ville'].apply(self._nettoyer_texte)
        if 'Niveau_Etude' in X_copy.columns:
            X_copy['Niveau_Etude'] = X_copy['Niveau_Etude'].apply(self._nettoyer_texte)

        # Top villes
        if 'Ville' in X_copy.columns:
            self.top_villes = self._get_top_villes(X_copy, 'Ville')

        # Ordinal Encoder pour Niveau_Etude
        if 'Niveau_Etude' in X_copy.columns:
            self.ordinal_encoder = OrdinalEncoder(
                categories=[self.ordre_etudes],
                handle_unknown='use_encoded_value',
                unknown_value=-1
            )
            self.ordinal_encoder.fit(X_copy[['Niveau_Etude']])

        # OneHot Encoder pour Ville (après filtrage)
        if 'Ville' in X_copy.columns:
            X_copy['Ville'] = X_copy['Ville'].where(X_copy['Ville'].isin(self.top_villes), 'autre')
            self.onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
            self.onehot_encoder.fit(X_copy[['Ville']])

        return self

    def transform(self, X):
        """Applique l'encodage appris."""
        X_copy = X.copy()

        # Nettoyage des textes
        if 'Ville' in X_copy.columns:
            X_copy['Ville'] = X_copy['Ville'].apply(self._nettoyer_texte)
        if 'Niveau_Etude' in X_copy.columns:
            X_copy['Niveau_Etude'] = X_copy['Niveau_Etude'].apply(self._nettoyer_texte)

        # Application du filtrage top villes
        if 'Ville' in X_copy.columns and self.top_villes:
            X_copy['Ville'] = X_copy['Ville'].where(X_copy['Ville'].isin(self.top_villes), 'autre')

        # Ordinal Encoding
        if 'Niveau_Etude' in X_copy.columns and self.ordinal_encoder:
            X_copy['Niveau_Etude_encoded'] = self.ordinal_encoder.transform(X_copy[['Niveau_Etude']])

        # OneHot Encoding
        if 'Ville' in X_copy.columns and self.onehot_encoder:
            encoded_data = self.onehot_encoder.transform(X_copy[['Ville']])
            col_names = self.onehot_encoder.get_feature_names_out(['Ville'])
            encoded_df = pd.DataFrame(encoded_data, columns=col_names, index=X_copy.index)
            X_copy = pd.concat([X_copy, encoded_df], axis=1)

        # Suppression des colonnes textuelles originales
        X_copy.drop(columns=['Niveau_Etude', 'Ville'], inplace=True, errors='ignore')

        return X_copy


# ==============================================================================
# TRANSFORMER 4 : SCALING MULTI-STRATÉGIE
# ==============================================================================
class MultiStrategyScaler(BaseEstimator, TransformerMixin):
    """
    Scaling avec 3 stratégies différentes :
    1. Log1p + StandardScaler → Salaire_Annuel, Ratio_Epargne_Salaire
    2. StandardScaler → Age
    3. RobustScaler → Score_Credit_Externe
    """
    def __init__(self, cols_log=None):
        self.cols_log = cols_log or ['Salaire_Annuel', 'Ratio_Epargne_Salaire']
        self.cols_std = ['Age']
        self.cols_robust = ['Score_Credit_Externe']

        self.scaler_log_std = StandardScaler()
        self.scaler_std = StandardScaler()
        self.scaler_robust = RobustScaler()

    def fit(self, X, y=None):
        """Apprend les paramètres de scaling sur le Train."""
        # Log + Standard
        if all(col in X.columns for col in self.cols_log):
            self.scaler_log_std.fit(np.log1p(X[self.cols_log]))

        # Standard
        if all(col in X.columns for col in self.cols_std):
            self.scaler_std.fit(X[self.cols_std])

        # Robust
        if all(col in X.columns for col in self.cols_robust):
            self.scaler_robust.fit(X[self.cols_robust])

        return self

    def transform(self, X):
        """Applique le scaling appris."""
        X_copy = X.copy()

        # Log + Standard
        if all(col in X_copy.columns for col in self.cols_log):
            X_copy[self.cols_log] = self.scaler_log_std.transform(np.log1p(X_copy[self.cols_log].clip(lower=0)))

        # Standard
        if all(col in X_copy.columns for col in self.cols_std):
            X_copy[self.cols_std] = self.scaler_std.transform(X_copy[self.cols_std])

        # Robust
        if all(col in X_copy.columns for col in self.cols_robust):
            X_copy[self.cols_robust] = self.scaler_robust.transform(X_copy[self.cols_robust])

        return X_copy


print(" Transformers créés avec succès !")


# ==============================================================================
# PIPELINE DE PREPROCESSING COMPLET
# ==============================================================================

def create_preprocessing_pipeline(config_ordinale=None):
    """
    Crée le pipeline de preprocessing complet.

    Parameters
    ----------
    config_ordinale : dict
        Dictionnaire avec l'ordre des variables ordinales
        Ex: {'Niveau_Etude': ['bac', 'licence', 'master', 'doctorat']}

    Returns
    -------
    Pipeline sklearn
    """
    if config_ordinale is None:
        config_ordinale = {'Niveau_Etude': ['bac', 'licence', 'master', 'doctorat']}

    preprocessing_pipeline = Pipeline([
        ('cleaning', DataCleaningTransformer(generic_missing_values=None)),
        ('feature_engineering', FeatureEngineeringTransformer()),
        ('imputation', SmartImputerTransformer(dict_ordinals=config_ordinale)),
        ('encoding', CustomEncodingTransformer()),
        ('scaling', MultiStrategyScaler())
    ])

    return preprocessing_pipeline